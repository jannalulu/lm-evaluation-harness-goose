{
  "results": {
    "humaneval_instruct": {
      "alias": "humaneval_instruct",
      "pass@1,create_test": 0.8170731707317073,
      "pass@1_stderr,create_test": 0.030281359995933534
    }
  },
  "group_subtasks": {
    "humaneval_instruct": []
  },
  "configs": {
    "humaneval_instruct": {
      "task": "humaneval_instruct",
      "dataset_path": "openai/openai_humaneval",
      "test_split": "test",
      "doc_to_text": "Write a solution to the following problem and make sure that it passes the tests:\n```{{prompt}}",
      "doc_to_target": "{{test}}\ncheck({{entry_point}})",
      "unsafe_code": true,
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "def pass_at_k(references: list[str], predictions: list[list[str]], k: list[int] = None):\n    global compute_\n    assert k is not None\n    if isinstance(k, int):\n        k = [k]\n    res = compute_.compute(\n        references=references,\n        predictions=predictions,\n        k=k,\n    )\n    return res[0]\n",
          "aggregation": "mean",
          "higher_is_better": true,
          "k": [
            1
          ]
        }
      ],
      "output_type": "generate_until",
      "generation_kwargs": {
        "until": [
          "\nclass",
          "\ndef",
          "\n#",
          "\nif",
          "\nprint"
        ],
        "max_gen_toks": 1024,
        "do_sample": false
      },
      "repeats": 1,
      "filter_list": [
        {
          "name": "create_test",
          "filter": [
            {
              "function": "custom",
              "filter_fn": "<function build_predictions_instruct at 0x76912c169990>"
            }
          ]
        }
      ],
      "should_decontaminate": false,
      "gen_prefix": "Here is the completed function:\n```python\n{{prompt}}\n",
      "metadata": {
        "version": 2.0,
        "pretrained": "Erland/Qwen3Softpick-8B-Base",
        "trust_remote_code": true
      }
    }
  },
  "versions": {
    "humaneval_instruct": 2.0
  },
  "n-shot": {
    "humaneval_instruct": 0
  },
  "higher_is_better": {
    "humaneval_instruct": {
      "pass_at_k": true
    }
  },
  "n-samples": {
    "humaneval_instruct": {
      "original": 164,
      "effective": 164
    }
  },
  "config": {
    "model": "hf",
    "model_args": "pretrained=Erland/Qwen3Softpick-8B-Base,trust_remote_code=True",
    "model_num_parameters": 8190735360,
    "model_dtype": "torch.bfloat16",
    "model_revision": "main",
    "model_sha": "a622a8e596866e014a8ee5e53413fe1704540a18",
    "batch_size": "16",
    "batch_sizes": [],
    "device": null,
    "use_cache": null,
    "limit": null,
    "bootstrap_iters": 100000,
    "gen_kwargs": null,
    "random_seed": 0,
    "numpy_seed": 1234,
    "torch_seed": 1234,
    "fewshot_seed": 1234
  },
  "git_hash": "9527321b",
  "date": 1749590866.8885837,
  "pretty_env_info": "'NoneType' object has no attribute 'splitlines'",
  "transformers_version": "4.52.4",
  "lm_eval_version": "0.4.8",
  "upper_git_hash": null,
  "tokenizer_pad_token": [
    "<|endoftext|>",
    "151643"
  ],
  "tokenizer_eos_token": [
    "<|im_end|>",
    "151645"
  ],
  "tokenizer_bos_token": [
    null,
    "None"
  ],
  "eot_token_id": 151645,
  "max_length": 40960,
  "task_hashes": {},
  "model_source": "hf",
  "model_name": "Erland/Qwen3Softpick-8B-Base",
  "model_name_sanitized": "Erland__Qwen3Softpick-8B-Base",
  "system_instruction": null,
  "system_instruction_sha": null,
  "fewshot_as_multiturn": false,
  "chat_template": null,
  "chat_template_sha": null,
  "start_time": 2833356.0565802,
  "end_time": 2833468.430176736,
  "total_evaluation_time_seconds": "112.3735965359956"
}