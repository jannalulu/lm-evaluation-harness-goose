{
  "results": {
    "humaneval_instruct": {
      "alias": "humaneval_instruct",
      "pass@1,create_test": 0.0,
      "pass@1_stderr,create_test": 0.0
    }
  },
  "group_subtasks": {
    "humaneval_instruct": []
  },
  "configs": {
    "humaneval_instruct": {
      "task": "humaneval_instruct",
      "dataset_path": "openai/openai_humaneval",
      "test_split": "test",
      "doc_to_text": "Write a solution to the following problem and make sure that it passes the tests:\n```{{prompt}}",
      "doc_to_target": "{{test}}\ncheck({{entry_point}})",
      "unsafe_code": true,
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "def pass_at_k(references: list[str], predictions: list[list[str]], k: list[int] = None):\n    global compute_\n    assert k is not None\n    if isinstance(k, int):\n        k = [k]\n    res = compute_.compute(\n        references=references,\n        predictions=predictions,\n        k=k,\n    )\n    return res[0]\n",
          "aggregation": "mean",
          "higher_is_better": true,
          "k": [
            1
          ]
        }
      ],
      "output_type": "generate_until",
      "generation_kwargs": {
        "until": [
          "\nclass",
          "\ndef",
          "\n#",
          "\nif",
          "\nprint"
        ],
        "max_gen_toks": 1024,
        "do_sample": false
      },
      "repeats": 1,
      "filter_list": [
        {
          "name": "create_test",
          "filter": [
            {
              "function": "custom",
              "filter_fn": "<function build_predictions_instruct at 0x7f92159f8d30>"
            }
          ]
        }
      ],
      "should_decontaminate": false,
      "gen_prefix": "Here is the completed function:\n```python\n{{prompt}}\n",
      "metadata": {
        "version": 2.0,
        "pretrained": "TRI-ML/mistral-supra",
        "trust_remote_code": true
      }
    }
  },
  "versions": {
    "humaneval_instruct": 2.0
  },
  "n-shot": {
    "humaneval_instruct": 0
  },
  "higher_is_better": {
    "humaneval_instruct": {
      "pass_at_k": true
    }
  },
  "n-samples": {
    "humaneval_instruct": {
      "original": 164,
      "effective": 164
    }
  },
  "config": {
    "model": "hf",
    "model_args": "pretrained=TRI-ML/mistral-supra,trust_remote_code=True",
    "model_num_parameters": 7812321280,
    "model_dtype": "torch.float32",
    "model_revision": "main",
    "model_sha": "819d065e4ad1ae6020f71390257f03fa465303d7",
    "batch_size": "64",
    "batch_sizes": [],
    "device": null,
    "use_cache": null,
    "limit": null,
    "bootstrap_iters": 100000,
    "gen_kwargs": null,
    "random_seed": 0,
    "numpy_seed": 1234,
    "torch_seed": 1234,
    "fewshot_seed": 1234
  },
  "git_hash": "d58c882",
  "date": 1748470860.8851383,
  "pretty_env_info": "'NoneType' object has no attribute 'splitlines'",
  "transformers_version": "4.49.0",
  "lm_eval_version": "0.4.8",
  "upper_git_hash": null,
  "tokenizer_pad_token": [
    "<unk>",
    "0"
  ],
  "tokenizer_eos_token": [
    "</s>",
    "2"
  ],
  "tokenizer_bos_token": [
    "<s>",
    "1"
  ],
  "eot_token_id": 2,
  "max_length": 2048,
  "task_hashes": {},
  "model_source": "hf",
  "model_name": "TRI-ML/mistral-supra",
  "model_name_sanitized": "TRI-ML__mistral-supra",
  "system_instruction": null,
  "system_instruction_sha": null,
  "fewshot_as_multiturn": false,
  "chat_template": null,
  "chat_template_sha": null,
  "start_time": 1812971.429581585,
  "end_time": 1813062.203517865,
  "total_evaluation_time_seconds": "90.77393627981655"
}